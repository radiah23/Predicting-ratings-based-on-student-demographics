---
title: "An Exploration of the Texas Education Agency 2022-2023 Accountability Ratings Dataset"
format: pdf
editor: visual
author: Radiah Khan, Mercer Mercer, Nafisa Mohamed, Catherine Weeks
bibliography: references.bib
---

# Introduction

Through this paper, we aim to address the question: Do schools in Texas with higher percentages of economically disadvantaged students have lower accountability ratings? To address this, we sourced our data from Texas’s annual academic accountability ratings, which it provides for all of its public and charter schools. This question is of particular interest now because the Academic accountability ratings are the benchmark the Texas Education Agency (TEA) uses to take over underperforming districts[@texaseducationagency2025]. This adds additional questions to what makes a school at risk for being taken over. The previous two districts to be taken over, Houston ISD and Fort Worth ISD, both had a large percentage of economically disadvantaged students. Some districts have begun redrawing their boundaries to avoid government takeovers[@edison2025]. If schools that predominantly serve economically disadvantaged students are closing to avoid a government takeover, this would cause an undue burden on those students, who would then have to travel further to get to classes, which can already be a barrier to education. Texas has also recently updated the criteria in its accountability rating system, which some teachers and superintendents claim has made earning a passing grade more difficult, potentially affecting whether student economic status influences academic ratings. Previous research has suggested a connection between a student's economic status and school performance. For example, a study from Stanford examining all public school districts in the United States found a strong relationship between district socioeconomic status and average academic achievement [@seanf.reardon2016]. Another study found a strong connection between student socioeconomic status and student achievement[@jenniferelizabethbarry2006]. But neither of these are recent or uses the data that Texas uses to internally select what it considers to be failing schools. Our paper aims to provide additional insight into how Texas’s academic achievement ratings relate to students' socioeconomic status, given the state’s new academic achievement rating system. Texas’s academic accountability rating system reports multiple variables containing information on school performance, but the ones of interest to us are as follows: Academic Growth Score, Overall Score, School Progress Score, and multiple variables indicating distinction in particular areas, which we have combined into a single variable that tracks total earned distinctions.

```{r}
library(readr)
School_Year_2022_2023_Statewide_Accountability_Ratings_20251119 <- read_csv("School_Year_2022-2023_Statewide_Accountability_Ratings_20251119.csv")
#View(School_Year_2022_2023_Statewide_Accountability_Ratings_20251119)
```

```{r}
library(janitor)
cleaned_name_school <- clean_names(School_Year_2022_2023_Statewide_Accountability_Ratings_20251119)
```

```{r}
colnames(cleaned_name_school)
```

```{r}
#Economically disadvantaged grouped by regions 
library(tidyverse)
data <-cleaned_name_school |>
  mutate(percent_economically_disadvantaged = 
           as.numeric(str_replace_all(percent_economically_disadvantaged, "[^0-9.]", "")))
```

```{r}
#changed to be highest avg
plot_economical_region <- data |>
 select(district , percent_economically_disadvantaged)|>
  group_by(district) |>
  summarise(avg_disadvantaged = mean(percent_economically_disadvantaged, na.rm = TRUE)) |>
  arrange(desc(avg_disadvantaged))
plot_economical_region
```

```{r}
highest_10_region <- plot_economical_region |> head(10)
```

## Plot 1

```{r}
#plotting the data 
#change interpretation of the plot to be about highest 10. Mention location, type, overall scores for these.
ggplot(highest_10_region, aes(x = reorder(district, avg_disadvantaged), 
                                   y = avg_disadvantaged, 
                                   fill = avg_disadvantaged)) +
  geom_col() +
  coord_flip() +
   scale_fill_gradient(
    low = "deepskyblue",   
    high = "springgreen3"  
  ) +
  labs(
    title = "Districts with the Highest Average Economically Disadvantaged Student Demographic (Top 10)",
    x = "District",
    y = "Economically Disadvantaged (%)",
    fill = "Disadvantaged %"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
      panel.grid.major=  element_blank(),
      panel.grid.minor = element_blank())
  
      
```

The horizontal bar chart of the ten districts with the lowest average percent economically disadvantaged highlights a small group of districts and charter schools with very low concentrations of economically disadvantaged students. Brock ISD and Trivium Academy stand out at the top of this list, followed by Leadership Prep School and a mix of charter and small district programs; the x-axis values show these averages are near or below single-digit percentages. This pattern suggests these districts are outliers in the dataset, and because they are small or specialized (charter and specialty schools), their demographic profiles differ substantially from the statewide mix — an important caveat when comparing demographic measures to performance outcomes.

## Plot 2 `Overall\nRating`

```{r}
colnames(data)
```

```{r}
ggplot(data, aes(x = overall_rating, fill = overall_rating)) +
  geom_bar() +
  scale_fill_brewer(palette = "YlGnBu") + 
  theme_minimal() +
  labs(
    title = "Count of Districts by Rating Categories",
    x = "Rating Category",
    y = "Number of Districts",
    fill = "Overall Rating"
  )+
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
      panel.grid.major=  element_blank(),
      panel.grid.minor = element_blank())


```

The rating-distribution bar chart shows most districts receive mid-to-high ratings: B and C are the most common categories (with B the largest, followed by C and A), while D, F, and Not Rated are substantially less frequent. In other words, most districts fall into the mid-to-high rating range, creating a central peak with short tails at both the high and low ends. This shape means the distribution is clustered rather than widely spread, so many districts have similar overall ratings and only a minority sit at the extremes. Practically, that implies comparisons based on letter grades will group many districts together and finer distinctions will rely on the underlying numeric scores or other measures to separate performance within that large central mass.

## Plot 3 `Academic Growth Score`

```{r}
#Academic growth score and overall rating
data <- data |>
  mutate(
    academic_growth_score = as.numeric(str_replace_all(academic_growth_score, "[^0-9.]", "")),
    overall_score = as.numeric(str_replace_all(overall_score, "[^0-9.]", ""))
  )

ggplot(data, aes(x = academic_growth_score, y = overall_score)) +
  geom_point(position = "jitter", na.rm = TRUE) +
  theme_minimal() +
  labs(
    title = "Academic Growth and Overall Rating",
    x = "Academic Growth Score",
    y = "Overall Score"
  ) +
  #scale_x_continuous() +
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
  )
```

The scatterplot of Academic Growth Score versus Overall Score reveals a clear positive relationship: higher academic growth scores tend to accompany higher overall scores, with many schools clustered along an upward trend from roughly 50–60 overall at lower growth values to 85–100 overall at higher growth values. The spread is wider at lower growth levels and tighter near the top, suggesting a ceiling effect where very high growth scores correspond to consistently high overall scores; this reinforces that academic growth is an important predictor of overall performance, although variability at lower growth levels indicates other factors also influence overall score.

# Variables

## Filtering it to 9-12

```{r}
filtered_df <- data |>
  filter(grades_served == "09 - 12")
filtered_df
```

```{r}
filtered_df_pivoted <- filtered_df |>
  pivot_longer(
    cols = starts_with("distinction_"),
    values_to = "distinction_status",
    names_to  = "Distinction Type"
  ) 
filtered_df_pivoted
```

```{r}
colnames(filtered_df_pivoted)
```

```{r}
final_df <- filtered_df_pivoted |>
  group_by(campus, district) |>
  summarise(
    number_of_students = first(number_of_students), #to get the unique values
    academic_growth_score = first(academic_growth_score),
    percent_economically_disadvantaged = first(percent_economically_disadvantaged),
    overall_score = first(overall_score),
    school_progress_score = first(school_progress_score),
    distinction_score = sum(distinction_status  == "Earned", na.rm = TRUE),
    .groups = "drop"
  )
final_df

```

# Methods

The data set used in this report is from the Texas Education Agency’s 2025 State, Region, District, and Campus-Level Accountability Report. The data in this report originates from public and charter schools in Texas overseen by the Texas Education Agency (TEA), who are required to submit all student standardized tests and other academic performance data [@texaseducationagency2025]. Each observation in this data set represents a different campus. The original data contains many variables related to school performance, but in this paper we will focus on schools’ Overall Score, their Academic Growth Scores, their Distinction Scores, the number of students, and the percentage of students who are economically disadvantaged.

The overall score represents the school’s final accountability rating on a 0-100 scale. It represents a schoolwide summary of academic performance, progress, and equity. This score is calculated by using three accountability domains: Student Achievement, School Progress, and Closing the Gaps. For this score, 70% is made up of either the Student Achievement or School progress (it picks the “better outcome”) and 30% of it is from their Closing the Gaps domain score (which evaluates how well a school is supporting the performance of specific students, specifically economically disadvantaged students, students from certain racial groups, and special needs students among others). The data handbook further explains how these were specifically calculated [@texaseducationagency2025]. The academic growth score is a measure of how much students improved academically over time. It is calculated using a raw growth score which is based on whether students met, exceeded, or fell short of STAAR progress (which is further defined in the data handbook). This raw growth score is then converted to a scaled score using a table, which then becomes the academic growth score, which is also measured on a 0-100 scale.

The distinction score indicators are calculated by comparing a school’s performance on multiple indicators to a group of similar campuses. If it places in the top quartile on at least 50% of indicators (for elementary and middle school) or 33% (for high school), it received the distinction. This means that the distinction score is whether or not the school performed exceptionally well compared to similar schools, and is a binary value of 0 (no distinction) or 1 (distinction) across multiple categories.

The percentage of students who are economically disadvantaged represents the percentage of students who are economically disadvantaged according to a few criteria. These include eligibility for free and reduced lunch prices and SNAP/TANF participation.

We also looked at the number of students in each school, which is a number representing the number of students enrolled in each campus.

### Data Processing Steps :

1.  The dataframe had column names that were either capitalized inconsistently/had multiple spaces in between words; which made parsing the names harder for R to work on. So we cleaned the column names. (e.g., `School Progress Score` $\rightarrow$ `school_progress_score`)

2.  The data was filtered to grades 09-12 using `grades_served` column to keep our results consistent and specific to only high school students.

3.  There were 7 columns of distinction for each school (Distinction ELA/Reading, Distinction Mathematics, Distinction Science, Distinction Soc Studies,Distinction Progress, DIstinction Closing the Gaps, Distinction PostSecondary Readiness). All of them had values of `Earned`, `Not Earned`, `NA`. We reshaped this wide data into long data and merged it into one single column named `distinction_status`.

4.  However, after creating the distinction_status column, each school had seven rows. To prevent this from creating inconsistencies in the results of the chosen model later, we created an additional column, `distinction_score`, which counts the number of times each school earned distinction out of seven and assigns a single score to each school.

5.  We removed all the rows with NA values.

6.  While working on this data set, the numeric variables had their values as characters and not numeric. So we converted them to numeric values for building our model.

7.  The final variables selected to later assess on are : `Number_of_students`,`academic_growth_score`, `percent_economically_disadvantaged,overall_score`, `school_progress_score`,`distinction_score`,
`campus`,`district\`

<center>

#### Data Observations Flow

**Initial dataset:** 10,253 observations

↓

**Filtered to grades 9–12:** 1,394 observations

↓

**After NA removal:** 1,356 observations

</center>
